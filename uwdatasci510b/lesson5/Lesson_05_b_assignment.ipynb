{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (Lesson 05)\n",
    "# Data Preparation and Feature Selection\n",
    "Steps in a data science project\n",
    "1. Acquire data\n",
    "2. Exploratory Data analysis (EDA)\n",
    "3. Data Processing\n",
    "    1. Data Preparation\n",
    "    2. Feature Selection\n",
    "4. Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "Python, like most programming languages, has pre-made software methods.  These pre-made software methods are organized and combined by topic into packages.  The packages that we want are:\n",
    "- numpy (numerical python)\n",
    "- pandas (panel data aka tables)\n",
    "- sklearn (sci-kit learn for predictive analytics)\n",
    "- matplotlib (data plotting for matrix-like data)  \n",
    "\n",
    "We need to \"import\" these packages so that we can use their methods in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "# Allow inline plotting in Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation on the Mammographic Masses Dataset (Mamm)\n",
    "### Acquire data\n",
    "We will get our data from the University of California, Irvine Machine Learning Repository.  Our dataset was used to determine the effectivity of radiological evaluations of breast cancer diagnoses in women who have breast tumors.  You can get some information on the data from here:  http://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI_RADS Age Shape Margin Density  Severity\n",
       "0       5  67     3      5       3         1\n",
       "1       4  43     1      1       ?         1\n",
       "2       5  58     4      5       3         1\n",
       "3       4  28     1      1       3         0\n",
       "4       5  74     1      5       ?         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv file:\n",
    "url = \"../data/mammographic_masses.data\"\n",
    "# Alternate data source:\n",
    "#url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data\"\n",
    "\n",
    "# Download the data\n",
    "Mamm = pd.read_csv(url, header=None)\n",
    "\n",
    "# Replace the default column names (0, 1, 2, 3, 4, 5) with meaningful names\n",
    "Mamm.columns = [\"BI_RADS\", \"Age\", \"Shape\", \"Margin\", \"Density\", \"Severity\"]\n",
    "\n",
    "Mamm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preliminary EDA:\n",
    "\"BI_RADS\", and \"Density\" are ordinal columns.  We will assume that they are numeric.  \n",
    "\"Age\" and \"Severity\" are numeric columns.    \n",
    "\"Shape\" and \"Margin\" are category columns but they are encoded as integers.  \n",
    "\n",
    "Show the actual data types of these columns.  Can you guess why the data types of these 5 columns are `object`?\n",
    "\n",
    "<span style=\"color:red\" float:right>[0 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    961.000000\n",
       "mean       0.463059\n",
       "std        0.498893\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Severity, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because they contain null value this is why they are object.\n",
    "Mamm[\"BI_RADS\"].describe()\n",
    "Mamm[\"Age\"].describe()\n",
    "Mamm[\"Shape\"].describe()\n",
    "Mamm[\"Margin\"].describe()\n",
    "Mamm[\"Density\"].describe()\n",
    "Mamm[\"Severity\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Data Processing\n",
    "In the following sections you will do the following to the Mamm dataframe:\n",
    "- Replace unusable entries with null/nan  \n",
    "- Change types of data.\n",
    "- Correct unexpected values (outliers)\n",
    "- decode category data    \n",
    "- Consolidate categories in category data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace Missing Values with Nulls\n",
    "Coerce all columns, even category columns, that contain missing values to numeric data using `pd.to_numeric`.  You might get an error, like `Unable to parse string`.  You need to tell `pd.to_numeric` that it should **coerce** the casting when it encounters a value that it cannot parse.  The category columns in this dataset are encoded as integers.  We will make use of that encoding.  Any non-numeric value will be replaced with a nan and you will get nans for missing numeric and category values.  After you replace all the non-numeric values, present the first five rows with `Mamm.head()`.\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI_RADS   Age  Shape  Margin  Density  Severity\n",
       "0      5.0  67.0    3.0     5.0      3.0         1\n",
       "1      4.0  43.0    1.0     1.0      NaN         1\n",
       "2      5.0  58.0    4.0     5.0      3.0         1\n",
       "3      4.0  28.0    1.0     1.0      3.0         0\n",
       "4      5.0  74.0    1.0     5.0      NaN         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coerce all the data to numeric data\n",
    "\n",
    "# Coercion will introduce nans/nulls for the non-numeric values in all columns\n",
    "# Because the categories are encoded as integers, the missing categories will also be nans/nulls after coercion.\n",
    "# Add code here\n",
    "\n",
    "for colName in Mamm.columns:\n",
    "    Mamm[colName] = pd.to_numeric(Mamm[colName],errors=\"coerce\")\n",
    "Mamm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace Outliers\n",
    "Values that are obviously incorrect are often replaced with averages.  Often, outlier replacements with averages are inappropriate because the extreme values have some meaning.  For instance, from the data dictionary we know that BI_RADS should range from 1 to 5.  BI_RADS values beyond 1 and 5 were added by physicians who did not adhere to the accepted range.  In this case, BI_RADS greater than 5 should be \"clipped\" at 5 and BI_RADS less than 1 should be \"clipped\" at 1. \n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    959.000000\n",
       "mean       4.289885\n",
       "std        0.656914\n",
       "min        1.000000\n",
       "25%        4.000000\n",
       "50%        4.000000\n",
       "75%        5.000000\n",
       "max        5.000000\n",
       "Name: BI_RADS, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap BI_RADS values to a range of 1 to 5\n",
    "# Add code here\n",
    "\n",
    "#Mamm[\"BI_RADS\"] = pd.to_numeric(Mamm[\"BI_RADS\"],downcast='integer')\n",
    "Mamm.loc[lambda df:df[\"BI_RADS\"] < 1,[\"BI_RADS\"]] = 1\n",
    "Mamm.loc[lambda df:df[\"BI_RADS\"] > 5,[\"BI_RADS\"]] = 5\n",
    "Mamm[\"BI_RADS\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate and decode category columns\n",
    "\n",
    "Decoding a category is when categories are coded as numbers and we replace those numbers with actual categories.  \n",
    "Consolidating (aka binning or grouping) of categories means that multiple categories are renamed to a single category.  \n",
    "The decoding and consolidating of categories can occur at the same time.  \n",
    "\n",
    "- Shape\n",
    "    - The original category codes are: round=1; oval=2; lobular=3; irregular=4;  \n",
    "    - The proper consolidated category decoding is: 1 $\\rightarrow$ oval; 2 $\\rightarrow$ oval; 3 $\\rightarrow$ lobular; 4 $\\rightarrow$ irregular;  \n",
    "- Margin\n",
    "    - The orginal category codes are: circumscribed=1; microlobulated=2; obscured=3; ill-defined=4; spiculated=5  \n",
    "    - The proper consolidated category decodes are: 1 $\\rightarrow$ circumscribed; 2 $\\rightarrow$ ill-defined; 3 $\\rightarrow$ ill-defined; 4 $\\rightarrow$ ill-defined; 5 $\\rightarrow$ spiculated;\n",
    "\n",
    "After you decode and consolidate, present the first five rows with `Mamm.head()`. \n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>lobular</td>\n",
       "      <td>spiculated</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>oval</td>\n",
       "      <td>circumscribed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>spiculated</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>oval</td>\n",
       "      <td>circumscribed</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>oval</td>\n",
       "      <td>spiculated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI_RADS   Age      Shape         Margin  Density  Severity\n",
       "0      5.0  67.0    lobular     spiculated      3.0         1\n",
       "1      4.0  43.0       oval  circumscribed      NaN         1\n",
       "2      5.0  58.0  irregular     spiculated      3.0         1\n",
       "3      4.0  28.0       oval  circumscribed      3.0         0\n",
       "4      5.0  74.0       oval     spiculated      NaN         1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The category columns are decoded and categories are consolidated\n",
    "\n",
    "# The Shape variable is decoded as follows:  1 and 2 to oval;  3 to lobular; 4 to irregular\n",
    "# Add code here\n",
    "\n",
    "Mamm.loc[lambda df:df[\"Shape\"] == 1, ['Shape']] = 'oval'\n",
    "Mamm.loc[lambda df:df[\"Shape\"] == 2, ['Shape']] = 'oval'\n",
    "Mamm.loc[lambda df:df[\"Shape\"] == 3, ['Shape']] = 'lobular'\n",
    "Mamm.loc[lambda df:df[\"Shape\"] == 4, ['Shape']] = 'irregular'\n",
    "Mamm[\"Shape\"] = Mamm[\"Shape\"].astype('category')\n",
    "#Mamm[\"Shape\"]\n",
    "# The Margin variable is decoded as follows:  1 to circumscribed;  2, 3, 4 to ill_defined; 5 to spiculated\n",
    "# Add code here\n",
    "#from pandas.api.types import CategoricalDtype\n",
    "#cat_dtype = CategoricalDtype()\n",
    "#MarginTable = {1:'circumscribed',2:'ill_defined',3:'ill_defined',4:'ill_defined',5:'spiculated'}\n",
    "#Mamm.assign(Margin = lambda df: MarginTable[df.Margin])\n",
    "\n",
    "Mamm.loc[lambda df:df.Margin == 1,'Margin'] = 'circumscribed'\n",
    "Mamm.loc[lambda df:df.Margin == 2,'Margin'] = 'ill_defined'\n",
    "Mamm.loc[lambda df:df.Margin == 3,'Margin'] = 'ill_defined'\n",
    "Mamm.loc[lambda df:df.Margin == 4,'Margin'] = 'ill_defined'\n",
    "Mamm.loc[lambda df:df.Margin == 5,'Margin'] = 'spiculated'\n",
    "Mamm[\"Margin\"] = Mamm[\"Margin\"].astype('category')\n",
    "\n",
    "# Present the first few rows\n",
    "# Add code here\n",
    "Mamm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some More EDA\n",
    "- Show the shape of the dataframe\n",
    "- Use the `pandas` `isna` method to show the distribution of nulls among the columns.\n",
    "  \n",
    "<span style=\"color:red\" float:right>[0 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       961\n",
       "unique        2\n",
       "top       False\n",
       "freq        913\n",
       "Name: Margin, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the shape of the data frame\n",
    "# Add code here\n",
    "\n",
    "# Show the distribution of nulls among the columns\n",
    "# Add code here\n",
    "Mamm['Margin'].isna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Rows with Multiple Missing Values\n",
    "When a row has too many missing values, then it should not be used.  We can stipulate a threshold requirement of available values per row.  We will require that each row contains at least 5 values.  This requirement means that no row is allowed more than 1 missing value.  \n",
    "Remove the rows that have more than one missing value.  \n",
    "- Use the `pandas` `dropna` method and set the `thresh` argument.  \n",
    "- Show the shape of the dataframe after you drop the rows with multiple nulls. \n",
    "- Use the `pandas` `isna` method to show the number of nulls per column after dropping rows with multiple nulls\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>961</td>\n",
       "      <td>961</td>\n",
       "      <td>961</td>\n",
       "      <td>961</td>\n",
       "      <td>961</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>959</td>\n",
       "      <td>956</td>\n",
       "      <td>930</td>\n",
       "      <td>913</td>\n",
       "      <td>885</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BI_RADS    Age  Shape Margin Density Severity\n",
       "count      961    961    961    961     961      961\n",
       "unique       2      2      2      2       2        1\n",
       "top      False  False  False  False   False    False\n",
       "freq       959    956    930    913     885      961"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows\n",
    "# Add code here\n",
    "Mamm.dropna(thresh=1) # thresh is not available in \n",
    "# Show the shape of the data frame\n",
    "# Add code here\n",
    "\n",
    "# Show the distribution of nulls among the columns\n",
    "# Add code here\n",
    "Mamm.isna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Missing Values\n",
    "Use the median values to impute missing values for true numerical columns (`Age`, `BI_RADS`, `Density`).  `Margin` and `Shape` originally looked numeric, but they are categorical.  Therefore, do not use median on `Margin` and `Shape`.  \n",
    "\n",
    "### Determine the imputation values for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing age values with the median \n",
    "MedianAge = np.nanmedian(Mamm.loc[:,\"Age\"])\n",
    "HasNanAge = pd.isnull(Mamm.loc[:,\"Age\"])\n",
    "print('Now we replace', HasNanAge.sum(),'missing age values with the age median (', MedianAge, ')')\n",
    "Mamm.loc[HasNanAge, \"Age\"] = MedianAge\n",
    "Mamm.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing values for BI_RADS and Density\n",
    "Assign the column medians to the null values in the respective numeric columns.\n",
    "- Use the `pandas` `isnull` method to identify the nulls\n",
    "- Use the `numpy` `nanmedian` to determine the median for imputation\n",
    "- Use the `pandas` `isna` method to show the number of nulls per column after the imputation   \n",
    "  \n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Imputation for BI_RADS\n",
    "# Add code here\n",
    "\n",
    "# Median Imputation for Density\n",
    "# Add code here\n",
    "\n",
    "# Distribution of nulls\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values for the two categorical columns\n",
    "- Use `pandas` `value_counts()` method to determine the distribution of categories in `Shape` and `Margin` before imputation.\n",
    "- Use `pandas` `isnull()` method to identify the missing values\n",
    "- Assign the most common value to the null values in the respective categorical columns. \n",
    "- After the imputation, use the `pandas` `isna` method to show the number of nulls after the imputation.\n",
    "- Use `pandas` `value_counts()` method to determine the distribution of categories after imputation.\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the distribution of categories for Shape\n",
    "# Add code here\n",
    "\n",
    "# Replace nulls in Shape with the most common category of Shape\n",
    "# Add code here\n",
    "\n",
    "# Determine the distribution of categories for Margin\n",
    "# Add code here\n",
    "\n",
    "# Replace nulls in Margin with the most common category of Margin\n",
    "# Add code here\n",
    "\n",
    "# Distribution of nulls\n",
    "# Add code here\n",
    "\n",
    "# Determine the distribution of categories for Shape\n",
    "# Add code here\n",
    "\n",
    "# Determine the distribution of categories for Margin\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode the categorical variables\n",
    "- Use `OneHotEncoder` from `sklearn.preprocessing` to one-hot encode the two categorical variables, `Shape` and `Margin`.\n",
    "- Make sure that the new columns have descriptive hybrid names by using the `get_feature_names_out` method.\n",
    "- Add the new binary columns to the dataframe.\n",
    "- drop the original columns, `Shape` and `Margin`\n",
    "- Show the first few rows of the dataframe.\n",
    "\n",
    "<span style=\"color:red\" float:right>[3 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get package\n",
    "# Add code here\n",
    "\n",
    "# One-hot-encode\n",
    "# Add code here\n",
    "\n",
    "# Create Column Names\n",
    "# Add code here\n",
    "\n",
    "# Add one-hot-encoded columns to dataframe\n",
    "# Add code here\n",
    "\n",
    "# Drop original categorical columns\n",
    "# Add code here\n",
    "\n",
    "# Show the first few rows\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Data Preparation on the Mammographic Masses Dataset (Mamm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection on the Indian  Liver Patient Dataset (ILPD)\n",
    "Feature selection is a process of removing features that are redundant and that could lead to overfitting, singular matrices, and other problems associated with high cardinality (Curse of dimensionality:  https://en.wikipedia.org/wiki/Curse_of_dimensionality)\n",
    "\n",
    "**Review of the Data Science Task**  \n",
    "A typical data science project will be to predict if an event will happen or not.  The prediction is done by a predictive model that is trained on the data that exists prior to the event.  The data scientist is tasked to create this predictive model by EDA, data preparation, model training, and finally model application.    \n",
    "\n",
    "**The Data Variety Problem**  \n",
    "Data preparation means that the data scientist will create features (table columns) from the available data sources.  Often, the data scientist is confronted with a huge variety of features.  The data scientist never intends to use all the available features because too many features are difficult to use and lead to bad predictive models.  Unfortunately, the data scientist doesn't know before training or application which features are useful.  \n",
    "\n",
    "**Feature Selection**  \n",
    "Feature (column) selection, sometimes called model selection, is a process where the data scientist chooses which features should be used for model training.  Feature elimination can be done in many ways:\n",
    "1. Based on domain understanding the data scientist can say that a feature is useless.  The problem with this approach is that it requires domain expertise and does not rely on a mathematically sound and reproducible method.\n",
    "2. Test if a feature is useful in a model (model selection).  The problem with this approach is that it requires a completed model and may be computationally very expensive.  Some methods are:\n",
    "   - Akaike Information Criterion (AIC)\n",
    "   - Bayesian Information Criterion (BIC)\n",
    "   - Minimum Description Length (MDL)\n",
    "3. Test feature (column) redundancy and get rid of a feature whose information already exists in another feature.  The benefit of this approach is a math/stats foundation that is easily reproduced and requires little computation.  The problem with this approach is that it is not as effective as domain understanding or testing a feature in a model.  This approach requires that we find redundancy between features.  We can measure redundancy in many ways, like:\n",
    "   - Correlation Coefficient\n",
    "   - **Mutual Information**\n",
    "\n",
    "It is this last item, **Mutual Information**, that we will use here to identify redundant columns (features) in a table.  These redundant columns are candidates for feature elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire Data\n",
    "\n",
    "We will get our data from the University of California, Irvine Machine Learning Repository. Our dataset was used to determine if blood test data could be sufficient to identify liver disease in rural areas with few physicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file:\n",
    "url = \"../data/Indian Liver Patient Dataset (ILPD).csv\"\n",
    "# Alternate data source:\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00225/Indian Liver Patient Dataset (ILPD).csv\"\n",
    "url = url.replace(\" \", \"%20\")\n",
    "\n",
    "# Download the data\n",
    "ILPD = pd.read_csv(url, header=None)\n",
    "\n",
    "# Replace the default column names (0, 1, 2, 3, 4, 5) with meaningful names\n",
    "ILPD.columns = [\"Age\",\"Gender\",\"DB\",\"TB\",\"Alkphos\",\"Sgpt\",\"Sgot\",\"TPr\",\"ALB\",\"AGRatio\",\"Selector\"]\n",
    "\n",
    "ILPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for ILPD\n",
    "- All columns should be numeric and continuous\n",
    "    - Remove binary columns (numeric and categorical) because their mutual information scores will be lower\n",
    "    - Remove any categorical columns\n",
    "- Remove or impute any missing values\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Binary Columns\n",
    "# Add Code here\n",
    "\n",
    "# Impute values or remove rows with nulls\n",
    "# Add Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "https://en.wikipedia.org/wiki/Mutual_information\n",
    "Below is a wrapper for determining the mutual information between two continuous (numeric) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "# x is the first input variable\n",
    "# y is the second input variable\n",
    "# bins is the number of discretized values that will be used for the two input variables\n",
    "def calc_MI(x, y, bins=80):\n",
    "    if (bins > 1):\n",
    "        c_xy = np.histogram2d(x, y, bins)[0]\n",
    "        mi = mutual_info_score(None, None, contingency = c_xy)\n",
    "    else:\n",
    "        mi = mutual_info_score(x, y)\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create method to list  all column pairs together with their mutual information score\n",
    "Write a method called `listMutualInformationScores`.  It uses the above method (`calc_MI`) in a loop to find the mutual information between all possible pairs of coulmns in the data.  The input to the function is the dataframe of continuous variables, specifically the prepared ILPD dataset.  \n",
    "\n",
    "The method returns a list of lists.  Each inner list contains three items:  the x-column, the y-column, and the mutual information score. The list of lists contains every possible pair of coulmns in the data.  The result should have a form similar to the following, except that the outer list is much longer and contains all possible column pairs:  \n",
    "`[['Alkphos', 'Sgot',    0.33],` <br/>\n",
    "` ['Sgot',    'AGRatio', 0.23],` <br/>\n",
    "` ['Age',     'Sgot',    0.35],` <br/>\n",
    "` ['Sgpt',    'AGRatio', 0.30],` <br/>\n",
    "` ['Sgot',    'ALB',     0.29],` <br/>\n",
    "` ['Sgot',    'TPr',     0.33]]` <br/>\n",
    "\n",
    "<span style=\"color:red\" float:right>[3 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the method listMutualInformationScores\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the method listMutualInformationScores\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Present the mutual information results\n",
    "- Package the output into a dataframe\n",
    "- Sort the rows in descending order of mutual information\n",
    "- Present the dataframe\n",
    "\n",
    "The first column could be x, the second column could be called y and the third column could be called mi.  x and y are the pair of columns pair and mi is the pair's mutual information score.  The result should have a form similar to the following:\n",
    "\n",
    "| x | y | mi |\n",
    "| --- | --- | --- |\n",
    "| Age | Sgot | 0.35 |\n",
    "| Sgot | TPr | 0.33 |\n",
    "| Alkphos | Sgot | 0.33 |\n",
    "| Sgpt | AGRatio | 0.30 |\n",
    "| Sgot | ALB | 0.29 |\n",
    "| Sgot | AGRatio | 0.23 |\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present the results as dataframe\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on Mutual Information in ILPD\n",
    "Lets assume a threshold of 1 for the mutual information score\n",
    "Which columns would you eliminate? Why?  To answer these questions, you may need to read-up on feature selection with mutual information score.\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add discussion here  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
